{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7378c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "631e7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path('/Users/khoinguyen/Documents/primock57')\n",
    "textGrid_dir = root_dir / 'scripts' / 'textgrid'\n",
    "transcript_dir = root_dir / 'transcripts'\n",
    "audio_dir = root_dir / 'audio'\n",
    "notes_dir = root_dir / 'notes'\n",
    "output_dir = root_dir / 'output'\n",
    "joined_transcripts_dir = output_dir / 'joined_transcripts'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a63fa2b",
   "metadata": {},
   "source": [
    "## Create transcript to SOAP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1af00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Convert TextGrid files to transcript files\n",
    "def convert_textgrid_to_transcripts():\n",
    "    print(\"Converting TextGrid files to transcripts...\")\n",
    "    subprocess.run([\n",
    "        \"python\", \"scripts/textgrid_to_transcript.py\",\n",
    "        f\"--transcript_path={transcript_dir}\",\n",
    "        f\"--output_path={output_dir / 'joined_transcripts'}\"\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "# 2: Extract utterances and align with audio\n",
    "def extract_utterances():\n",
    "    print(\"Extracting utterances from transcripts...\")\n",
    "    subprocess.run([\n",
    "         \"python\", \"scripts/extract_utterances.py\",\n",
    "        f\"--audio_path={audio_dir}\",\n",
    "        f\"--transcript_path={transcript_dir}\",\n",
    "        f\"--output_path={output_dir}\"\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    \n",
    "# 3: Parse SOAP-formatted note into sections\n",
    "def split_soap_sections(note_text: str) -> dict:\n",
    "    soap = {\"Subjective\": \"\", \"Objective\": \"\", \"Assessment\": \"\", \"Plan\": \"\"}\n",
    "    current_section = None\n",
    "\n",
    "    for line in note_text.splitlines():\n",
    "        line = line.strip()\n",
    "        if line.lower().startswith(\"subjective\"):\n",
    "            current_section = \"Subjective\"\n",
    "        elif line.lower().startswith(\"objective\"):\n",
    "            current_section = \"Objective\"\n",
    "        elif line.lower().startswith(\"assessment\"):\n",
    "            current_section = \"Assessment\"\n",
    "        elif line.lower().startswith(\"plan\"):\n",
    "            current_section = \"Plan\"\n",
    "        elif current_section:\n",
    "            soap[current_section] += line + \" \"\n",
    "    \n",
    "    return soap\n",
    "\n",
    "\n",
    "# Step 4: Pair transcripts with SOAP notes\n",
    "def pair_transcripts_and_notes() -> List[Tuple[str, dict]]:\n",
    "    print(\"Pairing transcripts with SOAP notes...\")\n",
    "    pairs = []\n",
    "    \n",
    "    transcript_files = sorted(joined_transcripts_dir.glob(\"*.txt\"))\n",
    "    note_files = sorted(notes_dir.glob(\"*.txt\"))\n",
    "\n",
    "    # Dict mapping stem (e.g. \"day1_consultation01\") to Path\n",
    "    note_dict = {note.stem.lower(): note for note in note_files}\n",
    "    print(f\"Found {len(transcript_files)} transcripts and {len(note_dict)} notes.\")\n",
    "\n",
    "    for transcript_file in transcript_files:\n",
    "        t_stem = transcript_file.stem.lower()\n",
    "        \n",
    "        if t_stem in note_dict:\n",
    "            print(f\"‚úÖ Match: {transcript_file.name} ‚Üî {note_dict[t_stem].name}\")\n",
    "            note_file = note_dict[t_stem]\n",
    "            transcript = transcript_file.read_text(encoding=\"utf-8\")\n",
    "            note = note_file.read_text(encoding=\"utf-8\")\n",
    "            soap = split_soap_sections(note)\n",
    "            pairs.append((transcript, soap))\n",
    "        else:\n",
    "            print(f\"‚ùå No match for: {transcript_file.name}\")\n",
    "\n",
    "    print(f\"Paired {len(pairs)} transcript-note files.\")\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9797063d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting TextGrid files to transcripts...\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day5_consultation04_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day3_consultation04_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day5_consultation12_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day4_consultation02_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day2_consultation02_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day1_consultation11_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day2_consultation05_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day4_consultation05_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day1_consultation08_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day3_consultation03_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day1_consultation07_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day5_consultation03_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day1_consultation10_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day2_consultation04_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day1_consultation09_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day4_consultation04_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day1_consultation06_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day3_consultation02_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day5_consultation02_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day5_consultation05_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day3_consultation05_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day1_consultation01_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day4_consultation03_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day2_consultation03_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day4_consultation06_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day2_consultation06_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day1_consultation12_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day4_consultation10_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day2_consultation09_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day1_consultation04_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day2_consultation10_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day4_consultation09_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day3_consultation07_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day1_consultation03_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day5_consultation07_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day1_consultation15_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day2_consultation01_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day5_consultation08_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day3_consultation08_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day4_consultation01_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day5_consultation11_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day1_consultation02_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day3_consultation06_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day5_consultation06_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day3_consultation10_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day1_consultation14_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day5_consultation09_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day5_consultation10_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day3_consultation09_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day4_consultation07_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day2_consultation07_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day1_consultation13_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day2_consultation08_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day5_consultation01_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day3_consultation01_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day4_consultation08_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/primock57/transcripts/day1_consultation05_doctor.TextGrid\n",
      "Extracting utterances from transcripts...\n",
      "Writing individual utterance audio files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 6999/7109 [00:12<00:00, 714.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing reference transcript file...\n",
      "Done!\n",
      "Pairing transcripts with SOAP notes...\n",
      "Found 57 transcripts and 57 notes.\n",
      "‚úÖ Match: day1_consultation01.txt ‚Üî day1_consultation01.txt\n",
      "‚úÖ Match: day1_consultation02.txt ‚Üî day1_consultation02.txt\n",
      "‚úÖ Match: day1_consultation03.txt ‚Üî day1_consultation03.txt\n",
      "‚úÖ Match: day1_consultation04.txt ‚Üî day1_consultation04.txt\n",
      "‚úÖ Match: day1_consultation05.txt ‚Üî day1_consultation05.txt\n",
      "‚úÖ Match: day1_consultation06.txt ‚Üî day1_consultation06.txt\n",
      "‚úÖ Match: day1_consultation07.txt ‚Üî day1_consultation07.txt\n",
      "‚úÖ Match: day1_consultation08.txt ‚Üî day1_consultation08.txt\n",
      "‚úÖ Match: day1_consultation09.txt ‚Üî day1_consultation09.txt\n",
      "‚úÖ Match: day1_consultation10.txt ‚Üî day1_consultation10.txt\n",
      "‚úÖ Match: day1_consultation11.txt ‚Üî day1_consultation11.txt\n",
      "‚úÖ Match: day1_consultation12.txt ‚Üî day1_consultation12.txt\n",
      "‚úÖ Match: day1_consultation13.txt ‚Üî day1_consultation13.txt\n",
      "‚úÖ Match: day1_consultation14.txt ‚Üî day1_consultation14.txt\n",
      "‚úÖ Match: day1_consultation15.txt ‚Üî day1_consultation15.txt\n",
      "‚úÖ Match: day2_consultation01.txt ‚Üî day2_consultation01.txt\n",
      "‚úÖ Match: day2_consultation02.txt ‚Üî day2_consultation02.txt\n",
      "‚úÖ Match: day2_consultation03.txt ‚Üî day2_consultation03.txt\n",
      "‚úÖ Match: day2_consultation04.txt ‚Üî day2_consultation04.txt\n",
      "‚úÖ Match: day2_consultation05.txt ‚Üî day2_consultation05.txt\n",
      "‚úÖ Match: day2_consultation06.txt ‚Üî day2_consultation06.txt\n",
      "‚úÖ Match: day2_consultation07.txt ‚Üî day2_consultation07.txt\n",
      "‚úÖ Match: day2_consultation08.txt ‚Üî day2_consultation08.txt\n",
      "‚úÖ Match: day2_consultation09.txt ‚Üî day2_consultation09.txt\n",
      "‚úÖ Match: day2_consultation10.txt ‚Üî day2_consultation10.txt\n",
      "‚úÖ Match: day3_consultation01.txt ‚Üî day3_consultation01.txt\n",
      "‚úÖ Match: day3_consultation02.txt ‚Üî day3_consultation02.txt\n",
      "‚úÖ Match: day3_consultation03.txt ‚Üî day3_consultation03.txt\n",
      "‚úÖ Match: day3_consultation04.txt ‚Üî day3_consultation04.txt\n",
      "‚úÖ Match: day3_consultation05.txt ‚Üî day3_consultation05.txt\n",
      "‚úÖ Match: day3_consultation06.txt ‚Üî day3_consultation06.txt\n",
      "‚úÖ Match: day3_consultation07.txt ‚Üî day3_consultation07.txt\n",
      "‚úÖ Match: day3_consultation08.txt ‚Üî day3_consultation08.txt\n",
      "‚úÖ Match: day3_consultation09.txt ‚Üî day3_consultation09.txt\n",
      "‚úÖ Match: day3_consultation10.txt ‚Üî day3_consultation10.txt\n",
      "‚úÖ Match: day4_consultation01.txt ‚Üî day4_consultation01.txt\n",
      "‚úÖ Match: day4_consultation02.txt ‚Üî day4_consultation02.txt\n",
      "‚úÖ Match: day4_consultation03.txt ‚Üî day4_consultation03.txt\n",
      "‚úÖ Match: day4_consultation04.txt ‚Üî day4_consultation04.txt\n",
      "‚úÖ Match: day4_consultation05.txt ‚Üî day4_consultation05.txt\n",
      "‚úÖ Match: day4_consultation06.txt ‚Üî day4_consultation06.txt\n",
      "‚úÖ Match: day4_consultation07.txt ‚Üî day4_consultation07.txt\n",
      "‚úÖ Match: day4_consultation08.txt ‚Üî day4_consultation08.txt\n",
      "‚úÖ Match: day4_consultation09.txt ‚Üî day4_consultation09.txt\n",
      "‚úÖ Match: day4_consultation10.txt ‚Üî day4_consultation10.txt\n",
      "‚úÖ Match: day5_consultation01.txt ‚Üî day5_consultation01.txt\n",
      "‚úÖ Match: day5_consultation02.txt ‚Üî day5_consultation02.txt\n",
      "‚úÖ Match: day5_consultation03.txt ‚Üî day5_consultation03.txt\n",
      "‚úÖ Match: day5_consultation04.txt ‚Üî day5_consultation04.txt\n",
      "‚úÖ Match: day5_consultation05.txt ‚Üî day5_consultation05.txt\n",
      "‚úÖ Match: day5_consultation06.txt ‚Üî day5_consultation06.txt\n",
      "‚úÖ Match: day5_consultation07.txt ‚Üî day5_consultation07.txt\n",
      "‚úÖ Match: day5_consultation08.txt ‚Üî day5_consultation08.txt\n",
      "‚úÖ Match: day5_consultation09.txt ‚Üî day5_consultation09.txt\n",
      "‚úÖ Match: day5_consultation10.txt ‚Üî day5_consultation10.txt\n",
      "‚úÖ Match: day5_consultation11.txt ‚Üî day5_consultation11.txt\n",
      "‚úÖ Match: day5_consultation12.txt ‚Üî day5_consultation12.txt\n",
      "Paired 57 transcript-note files.\n",
      "\n",
      "=== First Transcript Sample ===\n",
      " Doctor: Hello? Hi. Um, should we start? Yeah, okay. Hello how um. Good morning sir, how can I help you this morning?\n",
      "Patient: Hello, how are you?\n",
      "Patient: Oh hey, um, I've just had some diarrhea for the last three days, um, and it's been affecting me I need to stay close to the toilet. And, um, yeah, it's been affecting my day-to-day activities.\n",
      "Doctor: Sorry to hear that. Um, and and when you say diarrhea, what'd you mean by diarrhea? Do you mean you're going to the toilet more often? Or are yo\n",
      "\n",
      "=== First SOAP Sections ===\n",
      "\n",
      "--- Subjective ---\n",
      " \n",
      "\n",
      "--- Objective ---\n",
      " \n",
      "\n",
      "--- Assessment ---\n",
      " \n",
      "\n",
      "--- Plan ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7109/7109 [00:12<00:00, 555.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# üèÅ Run full pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    convert_textgrid_to_transcripts()\n",
    "    extract_utterances()\n",
    "    paired_data = pair_transcripts_and_notes()\n",
    "\n",
    "    # Show first sample\n",
    "    if paired_data:\n",
    "        transcript, soap = paired_data[0]\n",
    "        print(\"\\n=== First Transcript Sample ===\\n\", transcript[:500])\n",
    "        print(\"\\n=== First SOAP Sections ===\")\n",
    "        for section, content in soap.items():\n",
    "            print(f\"\\n--- {section} ---\\n{content[:300]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5c3685",
   "metadata": {},
   "source": [
    "## Training data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ad037b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_dir = Path(\"/Users/khoinguyen/Documents/primock57/output/joined_transcripts\")\n",
    "note_dir = Path(\"/Users/khoinguyen/Documents/primock57/notes\")\n",
    "output_path = Path(\"mistral_prompt_data.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4ec382a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved formatted data to /Users/khoinguyen/Documents/primock57/mistral_prompt_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "with output_path.open(\"w\", encoding=\"utf-8\") as outfile:\n",
    "    for transcript_file in sorted(transcript_dir.glob(\"*.txt\")):\n",
    "        base_name = transcript_file.stem\n",
    "        note_file = note_dir / f\"{base_name}.txt\"\n",
    "\n",
    "        if not note_file.exists():\n",
    "            print(f\"‚ùå Missing SOAP note for {base_name}\")\n",
    "            continue\n",
    "\n",
    "        transcript = transcript_file.read_text(encoding=\"utf-8\").strip()\n",
    "        note = note_file.read_text(encoding=\"utf-8\").strip()\n",
    "\n",
    "        prompt = f\"\"\"Below is a conversation between a doctor and a patient.\n",
    "\n",
    "Transcript:\n",
    "{transcript}\n",
    "\n",
    "Generate a SOAP note from this conversation.\"\"\"\n",
    "\n",
    "        entry = {\n",
    "            \"prompt\": prompt,\n",
    "            \"response\": note\n",
    "        }\n",
    "\n",
    "        outfile.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(f\"‚úÖ Saved formatted data to {output_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2062694f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output:\n",
      "  Subjective: The patient presented with symptoms of diarrhea (loose and watery stool), abdominal pain (cramp-like sensation in the lower left side), weakness, and shakiness for the past three days. He also reported a loss of appetite but has been able to maintain fluid intake. Vomiting was initially present but has since stopped. The patient did not report any blood in either his stools or vomit. The symptoms started around 3-4 days ago, and he remembers having takeaway from a Chinese restaurant during that time. He is an accountant and has been going to work despite the difficulties. He uses an inhaler for asthma, which is well-controlled.\n",
      "\n",
      "Objective: On physical examination, no abnormalities were noted. The patient's temperature was not measured, but he reported feeling hot around the onset of symptoms without a formal measurement.\n",
      "\n",
      "Assessment: The patient is likely suffering from gastroenteritis, possibly triggered by the Chinese takeaway he consumed. This condition typically presents with symptoms such as diarrhea, abdominal pain, and vomiting, often caused by viruses.\n",
      "\n",
      "Plan: Conservative management is recommended, including maintaining hydration through fluid intake, use of oral rehydration solutions like Dioralyte, paracetamol for fever and weakness, and rest. The patient should take time off work for the next 2-3 days. If symptoms persist beyond 3-4 days, further tests may be necessary, such as a stool sample for analysis. The patient was advised to return if symptoms do not improve or worsen.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"mistral_prompt_data.jsonl\") as f:\n",
    "    example = json.loads(next(f))\n",
    "\n",
    "response = subprocess.run(\n",
    "    [\"ollama\", \"run\", \"mistral\"],\n",
    "    input=example[\"prompt\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "print(\"Model Output:\\n\", response.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd4f250",
   "metadata": {},
   "source": [
    "## Evaluation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "969431a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"mistral_prompt_data.jsonl\"\n",
    "output_file = \"mistral_prompt_data_processed.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56f1a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Generating SOAP for example 1...\n",
      "üß† Generating SOAP for example 2...\n",
      "üß† Generating SOAP for example 3...\n",
      "üß† Generating SOAP for example 4...\n",
      "üß† Generating SOAP for example 5...\n",
      "üß† Generating SOAP for example 6...\n",
      "üß† Generating SOAP for example 7...\n",
      "üß† Generating SOAP for example 8...\n",
      "üß† Generating SOAP for example 9...\n",
      "üß† Generating SOAP for example 10...\n",
      "üß† Generating SOAP for example 11...\n",
      "üß† Generating SOAP for example 12...\n",
      "üß† Generating SOAP for example 13...\n",
      "üß† Generating SOAP for example 14...\n",
      "üß† Generating SOAP for example 15...\n",
      "üß† Generating SOAP for example 16...\n",
      "üß† Generating SOAP for example 17...\n",
      "üß† Generating SOAP for example 18...\n",
      "üß† Generating SOAP for example 19...\n",
      "üß† Generating SOAP for example 20...\n",
      "üß† Generating SOAP for example 21...\n",
      "üß† Generating SOAP for example 22...\n",
      "üß† Generating SOAP for example 23...\n",
      "üß† Generating SOAP for example 24...\n",
      "üß† Generating SOAP for example 25...\n",
      "üß† Generating SOAP for example 26...\n",
      "üß† Generating SOAP for example 27...\n",
      "üß† Generating SOAP for example 28...\n",
      "üß† Generating SOAP for example 29...\n",
      "üß† Generating SOAP for example 30...\n",
      "üß† Generating SOAP for example 31...\n",
      "üß† Generating SOAP for example 32...\n",
      "üß† Generating SOAP for example 33...\n",
      "üß† Generating SOAP for example 34...\n",
      "üß† Generating SOAP for example 35...\n",
      "üß† Generating SOAP for example 36...\n",
      "üß† Generating SOAP for example 37...\n",
      "üß† Generating SOAP for example 38...\n",
      "üß† Generating SOAP for example 39...\n",
      "üß† Generating SOAP for example 40...\n",
      "üß† Generating SOAP for example 41...\n",
      "üß† Generating SOAP for example 42...\n",
      "üß† Generating SOAP for example 43...\n",
      "üß† Generating SOAP for example 44...\n",
      "üß† Generating SOAP for example 45...\n",
      "üß† Generating SOAP for example 46...\n",
      "üß† Generating SOAP for example 47...\n",
      "üß† Generating SOAP for example 48...\n",
      "üß† Generating SOAP for example 49...\n",
      "üß† Generating SOAP for example 50...\n",
      "üß† Generating SOAP for example 51...\n",
      "üß† Generating SOAP for example 52...\n",
      "üß† Generating SOAP for example 53...\n",
      "üß† Generating SOAP for example 54...\n",
      "üß† Generating SOAP for example 55...\n",
      "üß† Generating SOAP for example 56...\n",
      "üß† Generating SOAP for example 57...\n",
      "‚úÖ Saved all generated notes to mistral_prompt_data_processed.jsonl\n"
     ]
    }
   ],
   "source": [
    "#  Looping over all 57 prompts and saving Mistral‚Äôs outputs\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for i, line in enumerate(infile, 1):\n",
    "        item = json.loads(line)\n",
    "        prompt = item[\"prompt\"]\n",
    "        reference = item[\"response\"]\n",
    "\n",
    "        print(f\"üß† Generating SOAP for example {i}...\")\n",
    "\n",
    "        result = subprocess.run(\n",
    "            [\"ollama\", \"run\", \"mistral\"],\n",
    "            input=prompt,\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "\n",
    "        generated = result.stdout.strip()\n",
    "\n",
    "        output = {\n",
    "            \"id\": i,\n",
    "            \"prompt\": prompt,\n",
    "            \"reference\": reference,\n",
    "            \"generated\": generated\n",
    "        }\n",
    "\n",
    "        outfile.write(json.dumps(output) + \"\\n\")\n",
    "\n",
    "print(f\"‚úÖ Saved all generated notes to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d96ee9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate with ROUGE\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1f55323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE Scores:\n",
      "\n",
      "rouge1: 0.5956\n",
      "rouge2: 0.2622\n",
      "rougeL: 0.3494\n"
     ]
    }
   ],
   "source": [
    "result_file = \"mistral_prompt_data_processed.jsonl\"\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "\n",
    "with open(result_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        generated = item[\"generated\"]\n",
    "        reference = item[\"reference\"]\n",
    "\n",
    "        score = scorer.score(reference, generated)\n",
    "        for key in scores:\n",
    "            scores[key].append(score[key].fmeasure)\n",
    "            \n",
    "# Calculate average scores\n",
    "avg_scores = {key: sum(values) / len(values) for key, values in scores.items()}\n",
    "\n",
    "print(\"Average ROUGE Scores:\\n\")\n",
    "for key, value in avg_scores.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36b9421",
   "metadata": {},
   "source": [
    "## Filter results that are missing SOAP section and use Gradio to create a web app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f45f78fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Split results into:\n",
      "- mistral_valid.jsonl (complete SOAP notes)\n",
      "- mistral_incomplete.jsonl (missing sections)\n"
     ]
    }
   ],
   "source": [
    "required_sections = [\"Subjective\", \"Objective\", \"Assessment\", \"Plan\"]\n",
    "\n",
    "def has_all_sections(text):\n",
    "    return all(re.search(rf\"(?i)\\b{section}\\b\", text) for section in required_sections)\n",
    "\n",
    "with open(\"mistral_prompt_data_processed.jsonl\", \"r\") as infile, \\\n",
    "     open(\"mistral_valid.jsonl\", \"w\") as valid_out, \\\n",
    "     open(\"mistral_incomplete.jsonl\", \"w\") as invalid_out:\n",
    "\n",
    "    for line in infile:\n",
    "        item = json.loads(line)\n",
    "        generated = item[\"generated\"]\n",
    "\n",
    "        if has_all_sections(generated):\n",
    "            valid_out.write(json.dumps(item) + \"\\n\")\n",
    "        else:\n",
    "            invalid_out.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "print(\"‚úÖ Split results into:\")\n",
    "print(\"- mistral_valid.jsonl (complete SOAP notes)\")\n",
    "print(\"- mistral_incomplete.jsonl (missing sections)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
