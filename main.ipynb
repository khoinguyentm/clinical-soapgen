{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7378c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "631e7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path('/Users/khoinguyen/Documents/clinical-soapgen')\n",
    "textGrid_dir = root_dir / 'scripts' / 'textgrid'\n",
    "transcript_dir = root_dir / 'transcripts'\n",
    "audio_dir = root_dir / 'audio'\n",
    "notes_dir = root_dir / 'notes'\n",
    "output_dir = root_dir / 'output'\n",
    "joined_transcripts_dir = output_dir / 'joined_transcripts'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a63fa2b",
   "metadata": {},
   "source": [
    "## Create transcript to SOAP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c1af00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Convert TextGrid files to transcript files\n",
    "def convert_textgrid_to_transcripts():\n",
    "    print(\"Converting TextGrid files to transcripts...\")\n",
    "    subprocess.run([\n",
    "        \"python\", \"scripts/textgrid_to_transcript.py\",\n",
    "        f\"--transcript_path={transcript_dir}\",\n",
    "        f\"--output_path={output_dir / 'joined_transcripts'}\"\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "# 2: Extract utterances and align with audio\n",
    "def extract_utterances():\n",
    "    print(\"Extracting utterances from transcripts...\")\n",
    "    subprocess.run([\n",
    "         \"python\", \"scripts/extract_utterances.py\",\n",
    "        f\"--audio_path={audio_dir}\",\n",
    "        f\"--transcript_path={transcript_dir}\",\n",
    "        f\"--output_path={output_dir}\"\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    \n",
    "# 3: Parse SOAP-formatted note into sections\n",
    "def split_soap_sections(note_text: str) -> dict:\n",
    "    soap = {\"Subjective\": \"\", \"Objective\": \"\", \"Assessment\": \"\", \"Plan\": \"\"}\n",
    "    current_section = None\n",
    "\n",
    "    for line in note_text.splitlines():\n",
    "        line = line.strip()\n",
    "        if line.lower().startswith(\"subjective\"):\n",
    "            current_section = \"Subjective\"\n",
    "        elif line.lower().startswith(\"objective\"):\n",
    "            current_section = \"Objective\"\n",
    "        elif line.lower().startswith(\"assessment\"):\n",
    "            current_section = \"Assessment\"\n",
    "        elif line.lower().startswith(\"plan\"):\n",
    "            current_section = \"Plan\"\n",
    "        elif current_section:\n",
    "            soap[current_section] += line + \" \"\n",
    "    \n",
    "    return soap\n",
    "\n",
    "\n",
    "# Step 4: Pair transcripts with SOAP notes\n",
    "def pair_transcripts_and_notes() -> List[Tuple[str, dict]]:\n",
    "    print(\"Pairing transcripts with SOAP notes...\")\n",
    "    pairs = []\n",
    "    \n",
    "    transcript_files = sorted(joined_transcripts_dir.glob(\"*.txt\"))\n",
    "    note_files = sorted(notes_dir.glob(\"*.txt\"))\n",
    "\n",
    "    # Dict mapping stem (e.g. \"day1_consultation01\") to Path\n",
    "    note_dict = {note.stem.lower(): note for note in note_files}\n",
    "    print(f\"Found {len(transcript_files)} transcripts and {len(note_dict)} notes.\")\n",
    "\n",
    "    for transcript_file in transcript_files:\n",
    "        t_stem = transcript_file.stem.lower()\n",
    "        \n",
    "        if t_stem in note_dict:\n",
    "            print(f\"✅ Match: {transcript_file.name} ↔ {note_dict[t_stem].name}\")\n",
    "            note_file = note_dict[t_stem]\n",
    "            transcript = transcript_file.read_text(encoding=\"utf-8\")\n",
    "            note = note_file.read_text(encoding=\"utf-8\")\n",
    "            soap = split_soap_sections(note)\n",
    "            pairs.append((transcript, soap))\n",
    "        else:\n",
    "            print(f\"❌ No match for: {transcript_file.name}\")\n",
    "\n",
    "    print(f\"Paired {len(pairs)} transcript-note files.\")\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9797063d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting TextGrid files to transcripts...\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day5_consultation04_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day3_consultation04_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day5_consultation12_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day4_consultation02_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day2_consultation02_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day1_consultation11_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day2_consultation05_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day4_consultation05_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day1_consultation08_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day3_consultation03_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day1_consultation07_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day5_consultation03_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day1_consultation10_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day2_consultation04_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day1_consultation09_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day4_consultation04_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day1_consultation06_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day3_consultation02_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day5_consultation02_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day5_consultation05_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day3_consultation05_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day1_consultation01_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day4_consultation03_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day2_consultation03_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day4_consultation06_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day2_consultation06_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day1_consultation12_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day4_consultation10_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day2_consultation09_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day1_consultation04_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day2_consultation10_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day4_consultation09_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day3_consultation07_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day1_consultation03_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day5_consultation07_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day1_consultation15_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day2_consultation01_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day5_consultation08_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day3_consultation08_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day4_consultation01_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day5_consultation11_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day1_consultation02_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day3_consultation06_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day5_consultation06_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day3_consultation10_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day1_consultation14_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day5_consultation09_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day5_consultation10_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day3_consultation09_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day4_consultation07_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day2_consultation07_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day1_consultation13_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day2_consultation08_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day5_consultation01_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day3_consultation01_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day4_consultation08_doctor.TextGrid\n",
      "/Users/khoinguyen/Documents/clinical-soapgen/transcripts/day1_consultation05_doctor.TextGrid\n",
      "Extracting utterances from transcripts...\n",
      "Writing individual utterance audio files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 7035/7109 [00:13<00:00, 615.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing reference transcript file...\n",
      "Done!\n",
      "Pairing transcripts with SOAP notes...\n",
      "Found 57 transcripts and 57 notes.\n",
      "✅ Match: day1_consultation01.txt ↔ day1_consultation01.txt\n",
      "✅ Match: day1_consultation02.txt ↔ day1_consultation02.txt\n",
      "✅ Match: day1_consultation03.txt ↔ day1_consultation03.txt\n",
      "✅ Match: day1_consultation04.txt ↔ day1_consultation04.txt\n",
      "✅ Match: day1_consultation05.txt ↔ day1_consultation05.txt\n",
      "✅ Match: day1_consultation06.txt ↔ day1_consultation06.txt\n",
      "✅ Match: day1_consultation07.txt ↔ day1_consultation07.txt\n",
      "✅ Match: day1_consultation08.txt ↔ day1_consultation08.txt\n",
      "✅ Match: day1_consultation09.txt ↔ day1_consultation09.txt\n",
      "✅ Match: day1_consultation10.txt ↔ day1_consultation10.txt\n",
      "✅ Match: day1_consultation11.txt ↔ day1_consultation11.txt\n",
      "✅ Match: day1_consultation12.txt ↔ day1_consultation12.txt\n",
      "✅ Match: day1_consultation13.txt ↔ day1_consultation13.txt\n",
      "✅ Match: day1_consultation14.txt ↔ day1_consultation14.txt\n",
      "✅ Match: day1_consultation15.txt ↔ day1_consultation15.txt\n",
      "✅ Match: day2_consultation01.txt ↔ day2_consultation01.txt\n",
      "✅ Match: day2_consultation02.txt ↔ day2_consultation02.txt\n",
      "✅ Match: day2_consultation03.txt ↔ day2_consultation03.txt\n",
      "✅ Match: day2_consultation04.txt ↔ day2_consultation04.txt\n",
      "✅ Match: day2_consultation05.txt ↔ day2_consultation05.txt\n",
      "✅ Match: day2_consultation06.txt ↔ day2_consultation06.txt\n",
      "✅ Match: day2_consultation07.txt ↔ day2_consultation07.txt\n",
      "✅ Match: day2_consultation08.txt ↔ day2_consultation08.txt\n",
      "✅ Match: day2_consultation09.txt ↔ day2_consultation09.txt\n",
      "✅ Match: day2_consultation10.txt ↔ day2_consultation10.txt\n",
      "✅ Match: day3_consultation01.txt ↔ day3_consultation01.txt\n",
      "✅ Match: day3_consultation02.txt ↔ day3_consultation02.txt\n",
      "✅ Match: day3_consultation03.txt ↔ day3_consultation03.txt\n",
      "✅ Match: day3_consultation04.txt ↔ day3_consultation04.txt\n",
      "✅ Match: day3_consultation05.txt ↔ day3_consultation05.txt\n",
      "✅ Match: day3_consultation06.txt ↔ day3_consultation06.txt\n",
      "✅ Match: day3_consultation07.txt ↔ day3_consultation07.txt\n",
      "✅ Match: day3_consultation08.txt ↔ day3_consultation08.txt\n",
      "✅ Match: day3_consultation09.txt ↔ day3_consultation09.txt\n",
      "✅ Match: day3_consultation10.txt ↔ day3_consultation10.txt\n",
      "✅ Match: day4_consultation01.txt ↔ day4_consultation01.txt\n",
      "✅ Match: day4_consultation02.txt ↔ day4_consultation02.txt\n",
      "✅ Match: day4_consultation03.txt ↔ day4_consultation03.txt\n",
      "✅ Match: day4_consultation04.txt ↔ day4_consultation04.txt\n",
      "✅ Match: day4_consultation05.txt ↔ day4_consultation05.txt\n",
      "✅ Match: day4_consultation06.txt ↔ day4_consultation06.txt\n",
      "✅ Match: day4_consultation07.txt ↔ day4_consultation07.txt\n",
      "✅ Match: day4_consultation08.txt ↔ day4_consultation08.txt\n",
      "✅ Match: day4_consultation09.txt ↔ day4_consultation09.txt\n",
      "✅ Match: day4_consultation10.txt ↔ day4_consultation10.txt\n",
      "✅ Match: day5_consultation01.txt ↔ day5_consultation01.txt\n",
      "✅ Match: day5_consultation02.txt ↔ day5_consultation02.txt\n",
      "✅ Match: day5_consultation03.txt ↔ day5_consultation03.txt\n",
      "✅ Match: day5_consultation04.txt ↔ day5_consultation04.txt\n",
      "✅ Match: day5_consultation05.txt ↔ day5_consultation05.txt\n",
      "✅ Match: day5_consultation06.txt ↔ day5_consultation06.txt\n",
      "✅ Match: day5_consultation07.txt ↔ day5_consultation07.txt\n",
      "✅ Match: day5_consultation08.txt ↔ day5_consultation08.txt\n",
      "✅ Match: day5_consultation09.txt ↔ day5_consultation09.txt\n",
      "✅ Match: day5_consultation10.txt ↔ day5_consultation10.txt\n",
      "✅ Match: day5_consultation11.txt ↔ day5_consultation11.txt\n",
      "✅ Match: day5_consultation12.txt ↔ day5_consultation12.txt\n",
      "Paired 57 transcript-note files.\n",
      "\n",
      "=== First Transcript Sample ===\n",
      " Doctor: Hello? Hi. Um, should we start? Yeah, okay. Hello how um. Good morning sir, how can I help you this morning?\n",
      "Patient: Hello, how are you?\n",
      "Patient: Oh hey, um, I've just had some diarrhea for the last three days, um, and it's been affecting me I need to stay close to the toilet. And, um, yeah, it's been affecting my day-to-day activities.\n",
      "Doctor: Sorry to hear that. Um, and and when you say diarrhea, what'd you mean by diarrhea? Do you mean you're going to the toilet more often? Or are yo\n",
      "\n",
      "=== First SOAP Sections ===\n",
      "\n",
      "--- Subjective ---\n",
      " \n",
      "\n",
      "--- Objective ---\n",
      " \n",
      "\n",
      "--- Assessment ---\n",
      " \n",
      "\n",
      "--- Plan ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7109/7109 [00:13<00:00, 523.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# 🏁 Run full pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    convert_textgrid_to_transcripts()\n",
    "    extract_utterances()\n",
    "    paired_data = pair_transcripts_and_notes()\n",
    "\n",
    "    # Show first sample\n",
    "    if paired_data:\n",
    "        transcript, soap = paired_data[0]\n",
    "        print(\"\\n=== First Transcript Sample ===\\n\", transcript[:500])\n",
    "        print(\"\\n=== First SOAP Sections ===\")\n",
    "        for section, content in soap.items():\n",
    "            print(f\"\\n--- {section} ---\\n{content[:300]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5c3685",
   "metadata": {},
   "source": [
    "## Training data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ad037b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_dir = Path(\"/Users/khoinguyen/Documents/clinical-soapgen/output/joined_transcripts\")\n",
    "note_dir = Path(\"/Users/khoinguyen/Documents/clinical-soapgen/notes\")\n",
    "output_path = Path(\"mistral_prompt_data.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4ec382a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved formatted data to /Users/khoinguyen/Documents/GitHub/clinical-soapgen/mistral_prompt_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "with output_path.open(\"w\", encoding=\"utf-8\") as outfile:\n",
    "    for transcript_file in sorted(transcript_dir.glob(\"*.txt\")):\n",
    "        base_name = transcript_file.stem\n",
    "        note_file = note_dir / f\"{base_name}.txt\"\n",
    "\n",
    "        if not note_file.exists():\n",
    "            print(f\"❌ Missing SOAP note for {base_name}\")\n",
    "            continue\n",
    "\n",
    "        transcript = transcript_file.read_text(encoding=\"utf-8\").strip()\n",
    "        note = note_file.read_text(encoding=\"utf-8\").strip()\n",
    "\n",
    "        prompt = f\"\"\"Below is a conversation between a doctor and a patient.\n",
    "\n",
    "Transcript:\n",
    "{transcript}\n",
    "\n",
    "Generate a SOAP note from this conversation.\"\"\"\n",
    "\n",
    "        entry = {\n",
    "            \"prompt\": prompt,\n",
    "            \"response\": note\n",
    "        }\n",
    "\n",
    "        outfile.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(f\"✅ Saved formatted data to {output_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2062694f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output:\n",
      "  Subjective:\n",
      "- The patient presented with symptoms of diarrhea for the past three days, including loose and watery stool, frequent bowel movements (6-7 times a day), lower abdominal pain on the left side that comes and goes, weakness, and shaking. He mentioned feeling shaky but not feverish and did experience vomiting at the start of the symptoms which has since stopped. The patient also reported a loss of appetite but is able to drink fluids.\n",
      "\n",
      "Objective:\n",
      "- Abdominal tenderness on left lower quadrant palpation, no rebound or guarding. Normal vital signs except for mild fever three days ago. No blood in stool or vomit.\n",
      "\n",
      "Assessment:\n",
      "- The patient appears to be suffering from gastroenteritis, possibly caused by a viral or bacterial infection, due to the presentation of diarrhea, abdominal pain, and vomiting, with no other significant past medical history. The patient reported eating at a Chinese restaurant four days ago, which may have been a trigger for the symptoms.\n",
      "\n",
      "Plan:\n",
      "- Conservative management including hydration with fluids and oral rehydration solution like Dioralyte, use of paracetamol for fever relief, rest, and time off work for two to three days. The patient was advised to return if symptoms persist beyond four days, and further tests may be required such as stool sampling for bacterial analysis. The patient understood the treatment plan and had no additional questions.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"mistral_prompt_data.jsonl\") as f:\n",
    "    example = json.loads(next(f))\n",
    "\n",
    "response = subprocess.run(\n",
    "    [\"ollama\", \"run\", \"mistral\"],\n",
    "    input=example[\"prompt\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "print(\"Model Output:\\n\", response.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd4f250",
   "metadata": {},
   "source": [
    "## Evaluation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "969431a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"mistral_prompt_data.jsonl\"\n",
    "output_file = \"mistral_prompt_data_processed.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c56f1a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Generating SOAP for example 1...\n",
      "🧠 Generating SOAP for example 2...\n",
      "🧠 Generating SOAP for example 3...\n",
      "🧠 Generating SOAP for example 4...\n",
      "🧠 Generating SOAP for example 5...\n",
      "🧠 Generating SOAP for example 6...\n",
      "🧠 Generating SOAP for example 7...\n",
      "🧠 Generating SOAP for example 8...\n",
      "🧠 Generating SOAP for example 9...\n",
      "🧠 Generating SOAP for example 10...\n",
      "🧠 Generating SOAP for example 11...\n",
      "🧠 Generating SOAP for example 12...\n",
      "🧠 Generating SOAP for example 13...\n",
      "🧠 Generating SOAP for example 14...\n",
      "🧠 Generating SOAP for example 15...\n",
      "🧠 Generating SOAP for example 16...\n",
      "🧠 Generating SOAP for example 17...\n",
      "🧠 Generating SOAP for example 18...\n",
      "🧠 Generating SOAP for example 19...\n",
      "🧠 Generating SOAP for example 20...\n",
      "🧠 Generating SOAP for example 21...\n",
      "🧠 Generating SOAP for example 22...\n",
      "🧠 Generating SOAP for example 23...\n",
      "🧠 Generating SOAP for example 24...\n",
      "🧠 Generating SOAP for example 25...\n",
      "🧠 Generating SOAP for example 26...\n",
      "🧠 Generating SOAP for example 27...\n",
      "🧠 Generating SOAP for example 28...\n",
      "🧠 Generating SOAP for example 29...\n",
      "🧠 Generating SOAP for example 30...\n",
      "🧠 Generating SOAP for example 31...\n",
      "🧠 Generating SOAP for example 32...\n",
      "🧠 Generating SOAP for example 33...\n",
      "🧠 Generating SOAP for example 34...\n",
      "🧠 Generating SOAP for example 35...\n",
      "🧠 Generating SOAP for example 36...\n",
      "🧠 Generating SOAP for example 37...\n",
      "🧠 Generating SOAP for example 38...\n",
      "🧠 Generating SOAP for example 39...\n",
      "🧠 Generating SOAP for example 40...\n",
      "🧠 Generating SOAP for example 41...\n",
      "🧠 Generating SOAP for example 42...\n",
      "🧠 Generating SOAP for example 43...\n",
      "🧠 Generating SOAP for example 44...\n",
      "🧠 Generating SOAP for example 45...\n",
      "🧠 Generating SOAP for example 46...\n",
      "🧠 Generating SOAP for example 47...\n",
      "🧠 Generating SOAP for example 48...\n",
      "🧠 Generating SOAP for example 49...\n",
      "🧠 Generating SOAP for example 50...\n",
      "🧠 Generating SOAP for example 51...\n",
      "🧠 Generating SOAP for example 52...\n",
      "🧠 Generating SOAP for example 53...\n",
      "🧠 Generating SOAP for example 54...\n",
      "🧠 Generating SOAP for example 55...\n",
      "🧠 Generating SOAP for example 56...\n",
      "🧠 Generating SOAP for example 57...\n",
      "✅ Saved all generated notes to mistral_prompt_data_processed.jsonl\n"
     ]
    }
   ],
   "source": [
    "#  Looping over all 57 prompts and saving Mistral’s outputs\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for i, line in enumerate(infile, 1):\n",
    "        item = json.loads(line)\n",
    "        prompt = item[\"prompt\"]\n",
    "        reference = item[\"response\"]\n",
    "\n",
    "        print(f\"🧠 Generating SOAP for example {i}...\")\n",
    "\n",
    "        result = subprocess.run(\n",
    "            [\"ollama\", \"run\", \"mistral\"],\n",
    "            input=prompt,\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "\n",
    "        generated = result.stdout.strip()\n",
    "\n",
    "        output = {\n",
    "            \"id\": i,\n",
    "            \"prompt\": prompt,\n",
    "            \"reference\": reference,\n",
    "            \"generated\": generated\n",
    "        }\n",
    "\n",
    "        outfile.write(json.dumps(output) + \"\\n\")\n",
    "\n",
    "print(f\"✅ Saved all generated notes to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d96ee9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate with ROUGE\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1f55323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE Scores:\n",
      "\n",
      "rouge1: 0.5898\n",
      "rouge2: 0.2584\n",
      "rougeL: 0.3462\n"
     ]
    }
   ],
   "source": [
    "result_file = \"mistral_prompt_data_processed.jsonl\"\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "\n",
    "with open(result_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        generated = item[\"generated\"]\n",
    "        reference = item[\"reference\"]\n",
    "\n",
    "        score = scorer.score(reference, generated)\n",
    "        for key in scores:\n",
    "            scores[key].append(score[key].fmeasure)\n",
    "            \n",
    "# Calculate average scores\n",
    "avg_scores = {key: sum(values) / len(values) for key, values in scores.items()}\n",
    "\n",
    "print(\"Average ROUGE Scores:\\n\")\n",
    "for key, value in avg_scores.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36b9421",
   "metadata": {},
   "source": [
    "## Filter results that are missing SOAP section and use Gradio to create a web app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45f78fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Split results into:\n",
      "- mistral_valid.jsonl (complete SOAP notes)\n",
      "- mistral_incomplete.jsonl (missing sections)\n"
     ]
    }
   ],
   "source": [
    "required_sections = [\"Subjective\", \"Objective\", \"Assessment\", \"Plan\"]\n",
    "\n",
    "def has_all_sections(text):\n",
    "    return all(re.search(rf\"(?i)\\b{section}\\b\", text) for section in required_sections)\n",
    "\n",
    "with open(\"mistral_prompt_data_processed.jsonl\", \"r\") as infile, \\\n",
    "     open(\"mistral_valid.jsonl\", \"w\") as valid_out, \\\n",
    "     open(\"mistral_incomplete.jsonl\", \"w\") as invalid_out:\n",
    "\n",
    "    for line in infile:\n",
    "        item = json.loads(line)\n",
    "        generated = item[\"generated\"]\n",
    "\n",
    "        if has_all_sections(generated):\n",
    "            valid_out.write(json.dumps(item) + \"\\n\")\n",
    "        else:\n",
    "            invalid_out.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "print(\"✅ Split results into:\")\n",
    "print(\"- mistral_valid.jsonl (complete SOAP notes)\")\n",
    "print(\"- mistral_incomplete.jsonl (missing sections)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "048078ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a395a7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_soap(prompt):\n",
    "    \"\"\"Call the Mistral model via subprocess and return the generated SOAP note.\"\"\"\n",
    "    result = subprocess.run(\n",
    "        [\"ollama\", \"run\", \"mistral\"],\n",
    "        input=prompt,\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    return result.stdout.strip()\n",
    "\n",
    "# Gradio interface\n",
    "gr.Interface(\n",
    "    fn=generate_soap,\n",
    "    inputs=gr.Textbox(lines=15, label=\"Paste transcript here\"),\n",
    "    outputs=gr.Textbox(lines=20, label=\"Generated SOAP note\"),\n",
    "    title=\"SOAP Note Generator\",\n",
    "    description=\"Paste a transcript of a doctor-patient conversation to generate a SOAP note using Mistral.\"\n",
    ").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
